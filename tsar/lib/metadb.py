"""
This file handles storage of metadata records.  TsarDB ingests
records (dicts) of a specified record_type that are created by
file_parser.Extractor and adds them to the managed dataframe.  This metadata is
what is intended to be ingested by search, browse, etc.

todo:
- error handle/resolve adding existing file
"""
import sys
import os
import pandas as pd
from tsar import METADB_PATH
from tsar.lib import file_parser
# from tsar import template
DB_PATH = os.path.join(METADB_PATH, 'tsar.pkl')


class TsarDB(object):
    """a wrapper around the database that contains tsar metadata.

    Notes:
    - each file is associated with a record (row) in the attribute self.df
    - records are generated by record type specific parsing functions in file_parser.py
    - The identity (index) of each record is defined by the path of the referenced file
    - the state of the file that generated the record is defined by `hash(file contents)`;
        `file contents` is defined on a per-(record type) basis in file_parser.py
    """
    def __init__(self, path=DB_PATH):
        self.path = path
        self.df = self._load_db()

    def update_record(self, record, record_id):
        """create/update the record for the file at `path`, parsed as `record_type`
        """
        self.df.loc[record_id] = record
        # self.write_db()

    # def update_records(self, folder, record_type):
    #     """determine all files of type `record_type` in `folder` and create/update all associated records in the db.
    #     """
    #     files = file_parser.return_files_by_record_type(folder, record_type)
    #     records = {}
    #     for file in files:
    #         records[file] = file_parser.parse_file(file, record_type)
    #     df_records = pd.DataFrame.from_dict(data=records, orient='index')
    #     self.df = pd.concat([self.df, df_records])

    def rm_record(self, path):
        """remove record at index location `path`
        """
        try:
            self.df = self.df.drop(path)
        except KeyError:
            print('warning: no record to remove at {}'.format(path))
            return

    def remove_db(self):
        """removes db
        """
        if os.path.exists(self.path):
            os.remove(self.path)

    def create_db(self, schema):
        """if db doesn't exist, create a new one.
        schema is a dict that maps column names to pandas dtypes.
        """
        if os.path.exists(self.path):
            raise FileExistsError('tsar db file already exists at {}'.format(self.path))
        self.df = pd.DataFrame(columns=schema.keys()).astype(schema)
        self.write_db()

    def write_db(self):
        """save state of df to current path
        """
        self.df.to_pickle(self.path)

    def _load_db(self):
        """loads the dataframe

        e.g. tsar_db.load_metadata(path=some_path, func=pd.DataFrame.read_pickle)
        """
        # try:
        if os.path.exists(self.path):
            df = pd.read_pickle(self.path)
        else:
            # print('no DataFrame file exists at {}; consider initializing one'.format(self.path))
            df = None
        return df


def return_newest_file(*file_paths):
    """compare files, return the most recently modified
    """
    file_mod_times = [os.path.getmtime(fn) for fn in file_paths]
    max_time = max(file_mod_times)
    index_val = file_mod_times.index(max_time)
    file = file_paths[index_val]
    return file


def return_oldest_file(*file_paths):
    """compare files, return the most recently modified
    """
    file_mod_times = [os.path.getmtime(fn) for fn in file_paths]
    max_time = min(file_mod_times)
    index_val = file_mod_times.index(max_time)
    file = file_paths[index_val]
    return file


def resolve_file_conflicts(*duplicate_paths, record_type):
    """resolves duplicate records

    Content uniqueness is specified by hash(file_contents).  The following specifies how conflicts are resolved:

    - for same name, same contents, keep oldest by modification time
    - same name, modified contents: keep newest by modification time
    """
    pass
